{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08235ed",
   "metadata": {},
   "source": [
    "# Trans2ray baggage xray object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ed5a2",
   "metadata": {},
   "source": [
    "## üì¶ Imports & Global Configuration\n",
    "\n",
    "In this section, we import all required libraries \n",
    "We also define global constants used throughout the notebook, such as:\n",
    "- Input image size\n",
    "- ImageNet normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Standard Libraries\n",
    "# ===============================\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# ===============================\n",
    "# Numerical & Data Handling\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# PyTorch Core\n",
    "# ===============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# ===============================\n",
    "# Computer Vision\n",
    "# ===============================\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "\n",
    "# ===============================\n",
    "# Visualization\n",
    "# ===============================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# ===============================\n",
    "# Utilities\n",
    "# ===============================\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ===============================\n",
    "# Global Constants\n",
    "# ===============================\n",
    "IMG_SIZE = 512\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6161d84",
   "metadata": {},
   "source": [
    "## üéØ Reproducibility & Random Seed Control\n",
    "\n",
    "To ensure **reproducible experiments**, we fix all relevant random seeds across different libraries and hardware backends.\n",
    "\n",
    "This function:\n",
    "- Sets the random seed for **Python**, **NumPy**, and **PyTorch**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    # python\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # torch (CPU)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # torch (CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # torch (MPS - Apple Silicon)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "    # deterministic behavior (slower but reproducible)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# üîπ call once at the very top\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0156f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17033700f50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a0e9e",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Paths & Class Mapping\n",
    "\n",
    "This cell defines:\n",
    "- The **root directory** of the DVXray dataset\n",
    "- Separate paths for **positive** and **negative** samples\n",
    "- A class-to-index mapping used for model training\n",
    "\n",
    "Basic assertions are included to ensure that the dataset paths exist before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab4b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(\"C:/Users/pc/Downloads/dvxray_dataset\")\n",
    "\n",
    "POS_DIR = ROOT / \"positive\"\n",
    "NEG_DIR = ROOT / \"negative\"\n",
    "\n",
    "CLASS_MAP = {\n",
    "    'Gun': 0, 'Knife': 1, 'Wrench': 2, 'Pliers': 3, 'Scissors': 4, 'Lighter': 5, 'Battery': 6,\n",
    "    'Bat': 7, 'Razor_blade': 8, 'Saw_blade': 9, 'Fireworks': 10, 'Hammer': 11,\n",
    "    'Screwdriver': 12, 'Dart': 13, 'Pressure_vessel': 14\n",
    "}\n",
    "\n",
    "assert POS_DIR.exists(), f\"missing: {POS_DIR}\"\n",
    "assert NEG_DIR.exists(), f\"missing: {NEG_DIR}\"\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607f37d",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Dataset Indexing\n",
    "\n",
    "This cell parses annotation files and builds a unified index for the dataset.\n",
    "\n",
    "For each sample, it collects:\n",
    "- Image paths (OL & SD views)\n",
    "- Annotation metadata\n",
    "- Object-level labels (if available)\n",
    "\n",
    "Both **positive** and **negative** folders are indexed and merged into a single list for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3535f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 16000\n"
     ]
    }
   ],
   "source": [
    "def read_json(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def index_folder(folder: Path):\n",
    "    items = []\n",
    "    json_paths = sorted(folder.glob(\"*.json\"))\n",
    "    for jp in json_paths:\n",
    "        ann = read_json(jp)\n",
    "        name = ann[\"name\"]\n",
    "\n",
    "        ol = folder / f\"{name}_OL.png\"\n",
    "        sd = folder / f\"{name}_SD.png\"\n",
    "\n",
    "        objs = ann.get(\"objects\", [])\n",
    "        if objs == \"None\" or objs is None:\n",
    "            objs = []\n",
    "\n",
    "        items.append({\n",
    "            \"name\": name,\n",
    "            \"folder\": folder.name,   # positive/negative\n",
    "            \"ol_path\": str(ol),\n",
    "            \"sd_path\": str(sd),\n",
    "            \"json_path\": str(jp),\n",
    "            \"objects\": objs\n",
    "        })\n",
    "    return items\n",
    "\n",
    "items = index_folder(POS_DIR) + index_folder(NEG_DIR)\n",
    "print(\"Total samples:\", len(items))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378cb1b",
   "metadata": {},
   "source": [
    "## üîç Dataset Integrity Check\n",
    "\n",
    "This cell performs basic sanity checks on the indexed dataset, including:\n",
    "- Counting **positive** and **negative** samples\n",
    "- Verifying the existence of **OL** and **SD** image files\n",
    "- Validating object labels against the predefined class map\n",
    "\n",
    "Summary statistics and example anomalies are printed to quickly identify potential data issues before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c33d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: 5000 negative: 11000\n",
      "total objects: 5087\n",
      "missing OL: 0 missing SD: 0\n",
      "unknown labels: 0\n"
     ]
    }
   ],
   "source": [
    "missing_ol = []\n",
    "missing_sd = []\n",
    "bad_json = []\n",
    "unknown_labels = []\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "obj_count = 0\n",
    "\n",
    "for it in items:\n",
    "    if it[\"folder\"] == \"positive\":\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        neg_count += 1\n",
    "\n",
    "    if not os.path.exists(it[\"ol_path\"]):\n",
    "        missing_ol.append(it[\"name\"])\n",
    "    if not os.path.exists(it[\"sd_path\"]):\n",
    "        missing_sd.append(it[\"name\"])\n",
    "\n",
    "    # label check\n",
    "    for o in it[\"objects\"]:\n",
    "        obj_count += 1\n",
    "        lab = o.get(\"label\")\n",
    "        if lab not in CLASS_MAP:\n",
    "            unknown_labels.append((it[\"name\"], lab))\n",
    "\n",
    "print(\"positive:\", pos_count, \"negative:\", neg_count)\n",
    "print(\"total objects:\", obj_count)\n",
    "print(\"missing OL:\", len(missing_ol), \"missing SD:\", len(missing_sd))\n",
    "print(\"unknown labels:\", len(unknown_labels))\n",
    "\n",
    "if missing_ol[:3]: print(\"missing_ol ex:\", missing_ol[:3])\n",
    "if missing_sd[:3]: print(\"missing_sd ex:\", missing_sd[:3])\n",
    "if unknown_labels[:3]: print(\"unknown_labels ex:\", unknown_labels[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33bff5",
   "metadata": {},
   "source": [
    "## üßπ Annotation Cleaning & Bounding Box Validation\n",
    "\n",
    "This cell validates and cleans annotation files by removing invalid bounding boxes.\n",
    "\n",
    "The cleaning process:\n",
    "- Checks bounding boxes for valid `(x1, y1, x2, y2)` format\n",
    "- Removes degenerate, zero-area, or negative-coordinate boxes\n",
    "- Ensures both **OL** and **SD** views are valid for each object\n",
    "- Creates a backup of original annotation files before modification\n",
    "\n",
    "A summary of modified files and removed objects is printed separately for positive and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719813ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touched JSON files (pos): 0 Removed objects: 0\n",
      "Touched JSON files (neg): 0 Removed objects: 0\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(\"C:/Users/pc/Downloads/dvxray_dataset\")\n",
    "POS_DIR = ROOT / \"positive\"\n",
    "NEG_DIR = ROOT / \"negative\"\n",
    "\n",
    "def valid_xyxy(bb):\n",
    "    if not isinstance(bb, list) or len(bb) != 4:\n",
    "        return False\n",
    "    x1,y1,x2,y2 = bb\n",
    "    # all zeros or degenerate\n",
    "    if (x1,y1,x2,y2) == (0,0,0,0):\n",
    "        return False\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return False\n",
    "    if x1 < 0 or y1 < 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def clean_json_file(js_path: Path, make_backup=True):\n",
    "    with open(js_path, \"r\") as f:\n",
    "        ann = json.load(f)\n",
    "\n",
    "    objs = ann.get(\"objects\", [])\n",
    "    if objs == \"None\" or objs is None:\n",
    "        return 0, 0  # unchanged, removed=0\n",
    "\n",
    "    kept = []\n",
    "    removed = 0\n",
    "    for o in objs:\n",
    "        ol_ok = valid_xyxy(o.get(\"ol_bb\"))\n",
    "        sd_ok = valid_xyxy(o.get(\"sd_bb\"))\n",
    "        if ol_ok and sd_ok:\n",
    "            kept.append(o)\n",
    "        else:\n",
    "            removed += 1\n",
    "\n",
    "    if removed == 0:\n",
    "        return 0, 0  # nothing removed\n",
    "\n",
    "    # backup\n",
    "    if make_backup:\n",
    "        bkp = js_path.with_suffix(\".json.bak\")\n",
    "        if not bkp.exists():\n",
    "            shutil.copy2(js_path, bkp)\n",
    "\n",
    "    # write cleaned\n",
    "    if len(kept) == 0:\n",
    "        ann[\"objects\"] = \"None\"\n",
    "    else:\n",
    "        ann[\"objects\"] = kept\n",
    "\n",
    "    with open(js_path, \"w\") as f:\n",
    "        json.dump(ann, f)\n",
    "\n",
    "    return removed, len(kept)\n",
    "\n",
    "def clean_folder(folder: Path):\n",
    "    removed_total = 0\n",
    "    touched = 0\n",
    "    for js_path in folder.glob(\"*.json\"):\n",
    "        removed, kept = clean_json_file(js_path)\n",
    "        if removed > 0:\n",
    "            touched += 1\n",
    "            removed_total += removed\n",
    "    return touched, removed_total\n",
    "\n",
    "t_pos, r_pos = clean_folder(POS_DIR)\n",
    "t_neg, r_neg = clean_folder(NEG_DIR)\n",
    "\n",
    "print(\"Touched JSON files (pos):\", t_pos, \"Removed objects:\", r_pos)\n",
    "print(\"Touched JSON files (neg):\", t_neg, \"Removed objects:\", r_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df224d",
   "metadata": {},
   "source": [
    "## üìê Bounding Box Consistency Check\n",
    "\n",
    "This cell performs an additional validation pass over all bounding boxes to detect:\n",
    "- Incorrect formats or missing values\n",
    "- Non-numeric coordinates\n",
    "- Degenerate boxes with zero or negative area\n",
    "- Bounding boxes with negative coordinates\n",
    "\n",
    "Detected anomalies are counted and a few examples are printed for manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59181f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_bbox: 0\n"
     ]
    }
   ],
   "source": [
    "bad_bbox = []\n",
    "for it in items:\n",
    "    for o in it[\"objects\"]:\n",
    "        for key in [\"ol_bb\", \"sd_bb\"]:\n",
    "            bb = o.get(key)\n",
    "            if not isinstance(bb, list) or len(bb) != 4:\n",
    "                bad_bbox.append((it[\"name\"], key, bb))\n",
    "                continue\n",
    "            x1,y1,x2,y2 = bb\n",
    "            if not all(isinstance(v, (int, float)) for v in bb):\n",
    "                bad_bbox.append((it[\"name\"], key, bb))\n",
    "                continue\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                bad_bbox.append((it[\"name\"], key, bb))\n",
    "            if x1 < 0 or y1 < 0:\n",
    "                bad_bbox.append((it[\"name\"], key, bb))\n",
    "ÿ∑\n",
    "print(\"bad_bbox:\", len(bad_bbox))\n",
    "if bad_bbox[:5]:\n",
    "    print(\"examples:\", bad_bbox[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80acab9",
   "metadata": {},
   "source": [
    "## üß† Two-View DVXray Dataset for DETR\n",
    "\n",
    "This section defines a custom PyTorch `Dataset` for the **DVXray two-view object detection task**, designed to be compatible with **DETR-style models**.\n",
    "\n",
    "Key features:\n",
    "- Supports **two synchronized views** per sample (OL & SD)\n",
    "- Loads annotations from JSON files\n",
    "- Cleans and filters invalid objects and labels\n",
    "- Resizes images and scales bounding boxes accordingly\n",
    "- Converts bounding boxes from `xyxy` format to **normalized `cxcywh`**\n",
    "- Applies **ImageNet normalization**\n",
    "\n",
    "The dataset outputs:\n",
    "- Two normalized image tensors (OL, SD)\n",
    "- A target dictionary containing labels and bounding boxes for both views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Configuration ----------\n",
    "CLASS_MAP = {\n",
    "    'Gun': 0, 'Knife': 1, 'Wrench': 2, 'Pliers': 3, 'Scissors': 4, 'Lighter': 5, 'Battery': 6,\n",
    "    'Bat': 7, 'Razor_blade': 8, 'Saw_blade': 9, 'Fireworks': 10, 'Hammer': 11,\n",
    "    'Screwdriver': 12, 'Dart': 13, 'Pressure_vessel': 14\n",
    "}\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "def xyxy_to_cxcywh_norm(boxes_xyxy: torch.Tensor, W: int, H: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert absolute bounding boxes from (x1, y1, x2, y2) format\n",
    "    to normalized (cx, cy, w, h) format in range [0, 1].\n",
    "    \"\"\"\n",
    "    if boxes_xyxy.numel() == 0:\n",
    "        return boxes_xyxy.reshape(0, 4)\n",
    "\n",
    "    x1, y1, x2, y2 = boxes_xyxy.unbind(-1)\n",
    "    cx = (x1 + x2) / 2.0\n",
    "    cy = (y1 + y2) / 2.0\n",
    "    bw = (x2 - x1)\n",
    "    bh = (y2 - y1)\n",
    "\n",
    "    out = torch.stack([cx / W, cy / H, bw / W, bh / H], dim=-1)\n",
    "    return out.clamp(0.0, 1.0)\n",
    "\n",
    "\n",
    "def resize_img_and_boxes_xyxy(img: Image.Image, boxes_xyxy: torch.Tensor, size: int):\n",
    "    \"\"\"\n",
    "    Resize image to (size, size) and scale bounding boxes accordingly.\n",
    "    \"\"\"\n",
    "    w0, h0 = img.size\n",
    "    img_resized = img.resize((size, size), resample=Image.BILINEAR)\n",
    "\n",
    "    if boxes_xyxy.numel() == 0:\n",
    "        return img_resized, boxes_xyxy.reshape(0, 4)\n",
    "\n",
    "    sx = size / w0\n",
    "    sy = size / h0\n",
    "\n",
    "    boxes = boxes_xyxy.clone()\n",
    "    boxes[:, [0, 2]] *= sx\n",
    "    boxes[:, [1, 3]] *= sy\n",
    "\n",
    "    boxes[:, [0, 2]] = boxes[:, [0, 2]].clamp(0, size - 1)\n",
    "    boxes[:, [1, 3]] = boxes[:, [1, 3]].clamp(0, size - 1)\n",
    "\n",
    "    return img_resized, boxes\n",
    "\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class DVXrayTwoViewDETR(Dataset):\n",
    "    \"\"\"\n",
    "    DVXray two-view dataset for DETR-style object detection.\n",
    "\n",
    "    Expected structure:\n",
    "    root/\n",
    "      Positive/*.json + *_OL.png + *_SD.png\n",
    "      Negative/*.json + *_OL.png + *_SD.png\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: str, split: str = \"all\", img_size: int = 512):\n",
    "        self.root = Path(root_dir)\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # If no explicit split folders exist, use the root directory\n",
    "        base_dir = self.root if split == \"all\" else (self.root / split)\n",
    "\n",
    "        pos_dir = base_dir / \"Positive\"\n",
    "        neg_dir = base_dir / \"Negative\"\n",
    "\n",
    "        assert pos_dir.exists(), f\"Missing folder: {pos_dir}\"\n",
    "        assert neg_dir.exists(), f\"Missing folder: {neg_dir}\"\n",
    "\n",
    "        self.samples = []\n",
    "\n",
    "        for folder in [pos_dir, neg_dir]:\n",
    "            for js_path in sorted(folder.glob(\"*.json\")):\n",
    "                ann = json.loads(js_path.read_text())\n",
    "                name = ann[\"name\"]\n",
    "\n",
    "                ol_path = folder / f\"{name}_OL.png\"\n",
    "                sd_path = folder / f\"{name}_SD.png\"\n",
    "\n",
    "                if not ol_path.exists() or not sd_path.exists():\n",
    "                    continue\n",
    "\n",
    "                objects = ann.get(\"objects\", [])\n",
    "                if objects == \"None\" or objects is None:\n",
    "                    objects = []\n",
    "\n",
    "                self.samples.append((ol_path, sd_path, objects, name))\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\n",
    "                \"No samples found. Check folder names (Positive/Negative) and file naming (*_OL.png, *_SD.png).\"\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ol_path, sd_path, objects, name = self.samples[idx]\n",
    "\n",
    "        # Load images\n",
    "        img_ol = Image.open(ol_path).convert(\"RGB\")\n",
    "        img_sd = Image.open(sd_path).convert(\"RGB\")\n",
    "\n",
    "        labels = []\n",
    "        boxes_ol = []\n",
    "        boxes_sd = []\n",
    "\n",
    "        # Parse annotations\n",
    "        for obj in objects:\n",
    "            label_name = obj[\"label\"]\n",
    "            if label_name not in CLASS_MAP:\n",
    "                continue\n",
    "\n",
    "            labels.append(CLASS_MAP[label_name])\n",
    "            boxes_ol.append(obj[\"ol_bb\"])  # xyxy\n",
    "            boxes_sd.append(obj[\"sd_bb\"])  # xyxy\n",
    "\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        boxes_ol = torch.tensor(boxes_ol, dtype=torch.float32).reshape(-1, 4)\n",
    "        boxes_sd = torch.tensor(boxes_sd, dtype=torch.float32).reshape(-1, 4)\n",
    "\n",
    "        # Resize images and scale bounding boxes (each view independently)\n",
    "        img_ol, boxes_ol = resize_img_and_boxes_xyxy(img_ol, boxes_ol, self.img_size)\n",
    "        img_sd, boxes_sd = resize_img_and_boxes_xyxy(img_sd, boxes_sd, self.img_size)\n",
    "\n",
    "        # Convert images to tensor and normalize\n",
    "        x_ol = TF.normalize(TF.to_tensor(img_ol), IMAGENET_MEAN, IMAGENET_STD)\n",
    "        x_sd = TF.normalize(TF.to_tensor(img_sd), IMAGENET_MEAN, IMAGENET_STD)\n",
    "\n",
    "        # Convert boxes to DETR-style normalized cxcywh format\n",
    "        boxes_ol_n = xyxy_to_cxcywh_norm(boxes_ol, self.img_size, self.img_size)\n",
    "        boxes_sd_n = xyxy_to_cxcywh_norm(boxes_sd, self.img_size, self.img_size)\n",
    "\n",
    "        target = {\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "            \"name\": name,\n",
    "            \"labels\": labels,        # class indices [0..14]\n",
    "            \"boxes_ol\": boxes_ol_n,  # [N, 4] normalized cxcywh\n",
    "            \"boxes_sd\": boxes_sd_n,  # [N, 4] normalized cxcywh\n",
    "        }\n",
    "\n",
    "        return x_ol, x_sd, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba0f5c",
   "metadata": {},
   "source": [
    "## üì¶ Custom Collate Function (Two-View DETR)\n",
    "\n",
    "This function defines a custom `collate_fn` for batching two-view inputs (OL & SD) while keeping detection targets as a list, as required by **DETR-style models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5adee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_two_view_detr(batch):\n",
    "    x_ol, x_sd, targets = zip(*batch)\n",
    "    return torch.stack(x_ol, 0), torch.stack(x_sd, 0), list(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6c0a4",
   "metadata": {},
   "source": [
    "## üö¶ Dataset Split & DataLoaders\n",
    "\n",
    "Split the DVXray dataset into train/val/test and create DataLoaders with:\n",
    "- Two-view batching (OL & SD)\n",
    "- Custom collate function\n",
    "- Reproducible seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)   \n",
    "\n",
    "full_dataset = DVXrayTwoViewDETR(\n",
    "    root_dir=ROOT,\n",
    "    split=\"all\",\n",
    "    img_size=512\n",
    ")\n",
    "n = len(full_dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [n_train, n_val, n_test],\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_two_view_detr,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g        \n",
    ")\n",
    "\n",
    "dl_val = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_two_view_detr,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "dl_test = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_two_view_detr,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c8856",
   "metadata": {},
   "source": [
    "## üèóÔ∏è CVFF Transformer Encoder (GCA + LFS)\n",
    "\n",
    "This module implements a **custom Transformer encoder** for two-view feature fusion in DVXray, inspired by Trans2Ray:\n",
    "\n",
    "Key features:\n",
    "- **Global Cross Attention (GCA)**: Cross attention between main and assist views, applied multiple times.\n",
    "- **Local Feature Selection (LFS)**: Encoder layers with block + MAWS for selecting top-K informative tokens.\n",
    "- **Two-view token fusion**: Combines main and assist features with global pooled tokens.\n",
    "- Output: `[N, B, C]` fused features for main view, ready for DETR-style decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MAWS: Mutual Attention Weight Selection\n",
    "# -----------------------------\n",
    "class MAWS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, contributions):\n",
    "        # x: attention [B, H, N, N] from a Block\n",
    "        # contributions: [B, H, N] or similar\n",
    "        contributions = contributions.mean(1)          # [B, N], mean over heads\n",
    "        weights = x[:, :, 0, :].mean(1)                # [B, N], mean over heads at query=0\n",
    "        scores = contributions * weights               # [B, N]\n",
    "        max_inx = torch.argsort(scores, dim=1, descending=True)\n",
    "        return None, max_inx\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Attention + MLP + Block\n",
    "# -----------------------------\n",
    "ACT2FN = {\"gelu\": torch.nn.functional.gelu}\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, B, C] -> [B, N, C] for attention computation\n",
    "        x = x.view(x.size(1), x.size(0), x.size(2))\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        q = self.wq(x).reshape(B, N, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "        k = self.wk(x).reshape(B, N, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "        v = self.wv(x).reshape(B, N, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "\n",
    "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale  # [B,H,N,N]\n",
    "        attn = attn_scores.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        out = (attn @ v).transpose(1,2).reshape(B, N, C)\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "\n",
    "        out = out.view(out.size(1), out.size(0), out.size(2))  # back to [N,B,C]\n",
    "\n",
    "        # contribution = softmax over keys for query=0\n",
    "        contribution = attn_scores.softmax(dim=-2)[:,:,:,0]  # [B,H,N]\n",
    "        return out, attn, contribution\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, dim, r=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, r*dim)\n",
    "        self.fc2 = nn.Linear(r*dim, dim)\n",
    "        self.act_fn = ACT2FN[\"gelu\"]\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight); nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6); nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attention_norm = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn_norm = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn = Mlp(dim)\n",
    "        self.attn = Attention(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, B, C]\n",
    "        h = x\n",
    "        x = self.attention_norm(x)\n",
    "        x, weights, contribution = self.attn(x)\n",
    "        x = x + h\n",
    "\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        return x, weights, contribution\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CrossAttention + CrossBlock\n",
    "# -----------------------------\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, d):\n",
    "        # x: [N2, B, C] -> [B, N2, C]\n",
    "        x = x.view(x.size(1), x.size(0), x.size(2))\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        # query from first d tokens (main)\n",
    "        q = self.wq(x[:, :d, :]).reshape(B, d, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "        k = self.wk(x).reshape(B, N, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "        v = self.wv(x).reshape(B, N, self.num_heads, C//self.num_heads).permute(0,2,1,3)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # [B,H,d,N]\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        out = (attn @ v).transpose(1,2).reshape(B, d, C)\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "\n",
    "        out = out.view(out.size(1), out.size(0), out.size(2))  # [d,B,C]\n",
    "        return out, attn\n",
    "\n",
    "\n",
    "class CrossBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = CrossAttention(d_model, num_heads=nhead, attn_drop=0.1, proj_drop=0.1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, d):\n",
    "        # src: [2N, B, C], d=N\n",
    "        s, attn = self.self_attn(src, d)\n",
    "        # only update main tokens\n",
    "        src_main = src[:d, :, :] + self.dropout(s)\n",
    "        return src_main, attn[:, :, :, d:]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CVFF Transformer Encoder\n",
    "# -----------------------------\n",
    "class CVFFTransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: src [N, 2B, C] (main + assist)\n",
    "    Output: memory_main [N, B, C]\n",
    "    Implements:\n",
    "      - GCA (2x CrossBlock)\n",
    "      - LFS with top-K token selection (MAWS)\n",
    "      - Optional feature fusion\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=256, nhead=8, num_layers=6,\n",
    "                 dim_feedforward=1024, dropout=0.1,\n",
    "                 gca_iters=2, topk=8, feature_fusion=True, use_norm=True):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.feature_fusion = feature_fusion\n",
    "        self.gca_iters = gca_iters\n",
    "        self.topk = topk\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model) if use_norm else None\n",
    "        self.crossblock = CrossBlock(d_model, nhead=nhead, dropout=dropout)\n",
    "        self.globle_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.maws = MAWS()\n",
    "        self.block = Block(d_model)\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None, pos=None):\n",
    "        # src: [N, 2B, C]\n",
    "        N, B2, C = src.shape\n",
    "        assert B2 % 2 == 0, \"Batch must be even: main+assist\"\n",
    "        B = B2 // 2\n",
    "\n",
    "        output = src\n",
    "\n",
    "        # ---- GCA ----\n",
    "        for _ in range(self.gca_iters):\n",
    "            output_main = output[:, :B, :]\n",
    "            output_assist = output[:, B:, :]\n",
    "            new_tokens = torch.cat((output_main, output_assist), dim=0)  # [2N,B,C]\n",
    "            output_main, _ = self.crossblock(new_tokens, N)\n",
    "            output = torch.cat((output_main, output_assist), dim=1)\n",
    "\n",
    "        # ---- LFS ----\n",
    "        tokens = [[] for _ in range(B)]\n",
    "        count = 0\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, pos=pos)\n",
    "            count += 1\n",
    "\n",
    "            output_main = output[:, :B, :]\n",
    "            output_assist = output[:, B:, :]\n",
    "\n",
    "            # global pooled token from main: [1,B,C]\n",
    "            output_m = self.globle_pool(output_main.permute(1,2,0)).permute(2,0,1)\n",
    "            new_output = torch.cat((output_m, output_assist), dim=0)  # [N+1,B,C]\n",
    "\n",
    "            # Block + MAWS\n",
    "            _, weights, contribution = self.block(new_output)\n",
    "\n",
    "            if self.feature_fusion:\n",
    "                _, selected_inx = self.maws(weights, contribution)\n",
    "                new_output_bnc = new_output.permute(1,0,2)  # [B,N+1,C]\n",
    "                K = min(self.topk, new_output_bnc.shape[1])\n",
    "                for i in range(B):\n",
    "                    tokens[i].extend(new_output_bnc[i, selected_inx[i,:K]])\n",
    "\n",
    "                # maintain main+assist for next layer except last\n",
    "                if count < self.num_layers:\n",
    "                    output = torch.cat((output_main, output_assist), dim=1)\n",
    "                else:\n",
    "                    output = output_main\n",
    "\n",
    "        # mean selected tokens\n",
    "        fused = []\n",
    "        for i in range(B):\n",
    "            if len(tokens[i]) == 0:\n",
    "                fused.append(torch.zeros(C, device=output.device, dtype=output.dtype))\n",
    "            else:\n",
    "                fused.append(torch.stack(tokens[i], dim=0).mean(0))\n",
    "        fused = torch.stack(fused, dim=0).unsqueeze(0)  # [1,B,C]\n",
    "\n",
    "        # final fusion\n",
    "        output_main = output[:, :B, :] if output.shape[1]==2*B else output\n",
    "        output = output_main + fused\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output  # [N,B,C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b3506",
   "metadata": {},
   "source": [
    "## üì¶ Bounding Box Utilities\n",
    "\n",
    "This cell provides helper functions for bounding box operations:\n",
    "\n",
    "- **Conversions**:\n",
    "  - `box_cxcywh_to_xyxy`: center-format ‚Üí corner-format\n",
    "  - `box_xyxy_to_cxcywh`: corner-format ‚Üí center-format\n",
    "- **Area computation**:\n",
    "  - `box_area`: computes area of boxes\n",
    "- **Generalized IoU**:\n",
    "  - `generalized_box_iou`: computes [N,M] GIoU between two sets of xyxy boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_cxcywh_to_xyxy(x):\n",
    "    # x: [...,4] in cxcywh normalized or absolute\n",
    "    cx, cy, w, h = x.unbind(-1)\n",
    "    b = [(cx - 0.5*w), (cy - 0.5*h),\n",
    "         (cx + 0.5*w), (cy + 0.5*h)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "def box_xyxy_to_cxcywh(x):\n",
    "    x0, y0, x1, y1 = x.unbind(-1)\n",
    "    b = [(x0 + x1)/2, (y0 + y1)/2, (x1 - x0), (y1 - y0)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "def box_area(boxes):\n",
    "    return (boxes[..., 2] - boxes[..., 0]).clamp(min=0) * (boxes[..., 3] - boxes[..., 1]).clamp(min=0)\n",
    "\n",
    "def generalized_box_iou(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    boxes1: [N,4] xyxy, boxes2: [M,4] xyxy\n",
    "    returns: [N,M]\n",
    "    \"\"\"\n",
    "    # intersection\n",
    "    lt = torch.max(boxes1[:, None, :2], boxes2[None, :, :2])\n",
    "    rb = torch.min(boxes1[:, None, 2:], boxes2[None, :, 2:])\n",
    "    wh = (rb - lt).clamp(min=0)\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "\n",
    "    area1 = box_area(boxes1)[:, None]\n",
    "    area2 = box_area(boxes2)[None, :]\n",
    "    union = area1 + area2 - inter + 1e-9\n",
    "    iou = inter / union\n",
    "\n",
    "    # enclosing box\n",
    "    lt_c = torch.min(boxes1[:, None, :2], boxes2[None, :, :2])\n",
    "    rb_c = torch.max(boxes1[:, None, 2:], boxes2[None, :, 2:])\n",
    "    wh_c = (rb_c - lt_c).clamp(min=0)\n",
    "    area_c = wh_c[:, :, 0] * wh_c[:, :, 1] + 1e-9\n",
    "\n",
    "    giou = iou - (area_c - union) / area_c\n",
    "    return giou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf00828",
   "metadata": {},
   "source": [
    "## üß≠ DETR-style 2D Sine-Cosine Positional Encoding\n",
    "\n",
    "`PositionEmbeddingSine` generates 2D sine-cosine positional encodings for transformer inputs.\n",
    "\n",
    "- **Input**: `[B, C, H, W]` feature map  \n",
    "- **Output**: `[B, 2*num_pos_feats, H, W]` positional encoding  \n",
    "- **Parameters**:\n",
    "  - `num_pos_feats`: number of features per dimension (default 128)\n",
    "  - `temperature`: frequency scaling factor (default 10000)\n",
    "  - `normalize`: whether to normalize positions to [0, scale]  \n",
    "  - `scale`: optional scaling factor (default `2*pi`)\n",
    "- **Logic**:  \n",
    "  - Compute normalized x/y coordinates  \n",
    "  - Apply sine to even channels, cosine to odd channels  \n",
    "  - Concatenate x/y embeddings along feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb633715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingSine(nn.Module):\n",
    "    \"\"\"\n",
    "    DETR-style 2D sine-cosine positional encoding.\n",
    "     [B, 2*num_pos_feats, H, W]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_pos_feats=128, temperature=10000, normalize=True, scale=None):\n",
    "        super().__init__()\n",
    "        self.num_pos_feats = num_pos_feats\n",
    "        self.temperature = temperature\n",
    "        self.normalize = normalize\n",
    "        if scale is None:\n",
    "            scale = 2 * math.pi\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,C,H,W]\n",
    "        B, _, H, W = x.shape\n",
    "        device = x.device\n",
    "        dtype = x.dtype\n",
    "\n",
    "        y_embed = torch.arange(H, device=device, dtype=dtype).unsqueeze(1).repeat(1, W)\n",
    "        x_embed = torch.arange(W, device=device, dtype=dtype).unsqueeze(0).repeat(H, 1)\n",
    "\n",
    "        if self.normalize:\n",
    "            y_embed = y_embed / (H - 1 + 1e-6) * self.scale\n",
    "            x_embed = x_embed / (W - 1 + 1e-6) * self.scale\n",
    "\n",
    "        dim_t = torch.arange(self.num_pos_feats, device=device, dtype=dtype)\n",
    "        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n",
    "\n",
    "        # [H,W,1] / [F] => [H,W,F]\n",
    "        pos_x = x_embed[..., None] / dim_t\n",
    "        pos_y = y_embed[..., None] / dim_t\n",
    "\n",
    "        \n",
    "        pos_x = torch.stack((pos_x[..., 0::2].sin(), pos_x[..., 1::2].cos()), dim=-1).flatten(-2)  # [H,W,F]\n",
    "        pos_y = torch.stack((pos_y[..., 0::2].sin(), pos_y[..., 1::2].cos()), dim=-1).flatten(-2)  # [H,W,F]\n",
    "\n",
    "        pos = torch.cat((pos_y, pos_x), dim=-1)               # [H,W,2F]\n",
    "        pos = pos.permute(2, 0, 1).unsqueeze(0).repeat(B, 1, 1, 1)  # [B,2F,H,W]\n",
    "        return pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f85ca",
   "metadata": {},
   "source": [
    "## üèó ResNet Backbone with Frozen BatchNorm\n",
    "\n",
    "This cell defines a **ResNet18 backbone** for feature extraction with frozen batch normalization.\n",
    "\n",
    "- **FrozenBatchNorm2d**: BatchNorm layers with fixed parameters (no running stats update).  \n",
    "- **ResNetBackbone**:\n",
    "  - Loads ResNet18 architecture.\n",
    "  - Replaces standard BatchNorm2d with `FrozenBatchNorm2d`.\n",
    "  - Projects the last feature map to `out_channels` (default 256).\n",
    "  - Freezes all layers except `layer4` and the projection layer.\n",
    "  - Optionally loads pretrained weights from a local file.\n",
    "\n",
    "- **Forward Pass**:  \n",
    "  1. Stem: conv1 ‚Üí bn1 ‚Üí relu ‚Üí maxpool  \n",
    "  2. Residual layers: layer1 ‚Üí layer2 ‚Üí layer3 ‚Üí layer4  \n",
    "  3. Projection to desired channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671fcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from C:/Users/pc/Desktop/xray project/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_6972\\263561293.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded successfully.\n",
      "ResNetBackbone(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (proj): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Frozen BatchNorm\n",
    "# -----------------------------\n",
    "class FrozenBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(FrozenBatchNorm2d, self).__init__()\n",
    "        # Buffers to store weights, bias, running mean/var (not trainable)\n",
    "        self.register_buffer(\"weight\", torch.ones(num_features))\n",
    "        self.register_buffer(\"bias\", torch.zeros(num_features))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features))\n",
    "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.weight / (self.running_var + 1e-5).sqrt()\n",
    "        return x * scale + self.bias\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ResNet Backbone\n",
    "# -----------------------------\n",
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, out_channels=256, pretrained=False, model_weights_path=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load ResNet18 architecture without pretrained weights\n",
    "        m = torchvision.models.resnet18(weights=None)\n",
    "\n",
    "        # Stem: conv1 ‚Üí bn1 ‚Üí relu ‚Üí maxpool\n",
    "        self.stem = nn.Sequential(\n",
    "            m.conv1, \n",
    "            m.bn1,  # standard BatchNorm\n",
    "            m.relu, \n",
    "            m.maxpool\n",
    "        )\n",
    "        self.layer1 = m.layer1\n",
    "        self.layer2 = m.layer2\n",
    "        self.layer3 = m.layer3\n",
    "        self.layer4 = m.layer4  # last layer remains trainable\n",
    "\n",
    "        # Project final channels to out_channels\n",
    "        self.proj = nn.Conv2d(512, out_channels, kernel_size=1)\n",
    "\n",
    "        # Freeze all layers except layer4 and projection\n",
    "        self.freeze_layers()\n",
    "\n",
    "        # Load pretrained weights from file if provided\n",
    "        if model_weights_path:\n",
    "            self.load_weights(model_weights_path)\n",
    "\n",
    "    def freeze_layers(self):\n",
    "        # Freeze all parameters except layer4 and proj\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"layer4\" not in name and \"proj\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def load_weights(self, model_weights_path):\n",
    "        \"\"\"\n",
    "        Load pretrained weights from local file.\n",
    "        Only layers present in model dict are loaded.\n",
    "        \"\"\"\n",
    "        print(f\"Loading weights from {model_weights_path}\")\n",
    "        checkpoint = torch.load(model_weights_path)\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "        print(\"Weights loaded successfully.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through stem and residual layers\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)      # [B,512,H',W']\n",
    "        x = self.proj(x)        # [B,256,H',W']\n",
    "        return x\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model_weights_path = \"C:/Users/pc/Desktop/xray project/resnet18-5c106cde.pth\"\n",
    "model = ResNetBackbone(out_channels=256, pretrained=False, model_weights_path=model_weights_path)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7ccbe",
   "metadata": {},
   "source": [
    "## üß© MLP & DETR Decoder\n",
    "\n",
    "This cell defines the **MLP head** and a **Transformer-based DETR decoder**:\n",
    "\n",
    "### `MLP`\n",
    "- Fully connected feedforward network.\n",
    "- `num_layers` linear layers with ReLU activations except for the last layer.\n",
    "- Input ‚Üí Hidden ‚Üí ‚Ä¶ ‚Üí Output dimensions configurable.\n",
    "\n",
    "### `DETRDecoder`\n",
    "- Standard Transformer decoder (PyTorch `nn.TransformerDecoder`).\n",
    "- Input:\n",
    "  - `tgt`: target queries `[num_queries, B, C]`\n",
    "  - `memory`: encoder memory `[N, B, C]`\n",
    "  - `pos` / `query_pos`: optional positional encodings\n",
    "- Output: decoded feature `[num_queries, B, C]` normalized via LayerNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "423a7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            in_d = input_dim if i == 0 else hidden_dim\n",
    "            out_d = output_dim if i == num_layers - 1 else hidden_dim\n",
    "            layers.append(nn.Linear(in_d, out_d))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.layers):\n",
    "            x = l(x)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class DETRDecoder(nn.Module):\n",
    "    def __init__(self, d_model=256, nhead=8, num_layers=6, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=False\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, tgt, memory, pos=None, query_pos=None):\n",
    "        # tgt: [num_queries,B,C]\n",
    "        # memory: [N,B,C]\n",
    "        q = tgt if query_pos is None else tgt + query_pos\n",
    "        k = memory if pos is None else memory + pos\n",
    "        hs = self.decoder(q, k)     # [num_queries,B,C]\n",
    "        hs = self.norm(hs)\n",
    "        return hs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51c311",
   "metadata": {},
   "source": [
    "## üöÄ Trans2Ray Model\n",
    "\n",
    "This cell implements the **full Trans2Ray detection model**:\n",
    "\n",
    "### Architecture:\n",
    "1. **Backbone**: `ResNetBackbone` extracts features from both OL and SD views.\n",
    "2. **Positional Encoding**: `PositionEmbeddingSine` applied to OL features.\n",
    "3. **CVFF Encoder**: `CVFFTransformerEncoder` performs:\n",
    "   - GCA (Global Cross Attention)\n",
    "   - LFS (Layer-wise Feature Selection)\n",
    "   - MAWS + Block fusion\n",
    "4. **DETR Decoder**: Standard transformer decoder for object queries.\n",
    "5. **Heads**:\n",
    "   - `class_embed`: predicts class probabilities (+1 for no-object)\n",
    "   - `bbox_embed`: predicts normalized bounding boxes in cxcywh format.\n",
    "\n",
    "### Forward Pass:\n",
    "- Input: `x_ol`, `x_sd` ‚Üí feature extraction via backbone.\n",
    "- Flatten spatial dims ‚Üí `[N, B, C]` for both views.\n",
    "- Concatenate main + assist features ‚Üí feed to CVFF encoder.\n",
    "- Decoder uses learned query embeddings to attend encoder memory.\n",
    "- Output: \n",
    "  - `\"pred_logits\"` ‚Üí class predictions `[B, Q, num_classes+1]`\n",
    "  - `\"pred_boxes\"` ‚Üí bounding boxes `[B, Q, 4]` (normalized cxcywh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d120409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trans2RayModel(nn.Module):\n",
    "    def __init__(self, num_classes=15, num_queries=100, d_model=256,\n",
    "                 nhead=8, enc_layers=6, dec_layers=6):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_queries = num_queries\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.backbone = ResNetBackbone(out_channels=d_model)\n",
    "        self.pos_enc = PositionEmbeddingSine(num_pos_feats=d_model//2)  # => 256\n",
    "\n",
    "        # EXACT CVFF encoder (GCA+LFS+MAWS+Block)\n",
    "        self.encoder = CVFFTransformerEncoder(\n",
    "            d_model=d_model, nhead=nhead, num_layers=enc_layers,\n",
    "            dim_feedforward=1024, dropout=0.1, gca_iters=2, topk=8,\n",
    "            feature_fusion=True, use_norm=True\n",
    "        )\n",
    "        self.decoder = DETRDecoder(d_model=d_model, nhead=nhead, num_layers=dec_layers, dim_feedforward=1024)\n",
    "\n",
    "        self.query_embed = nn.Embedding(num_queries, d_model)\n",
    "        self.class_embed = nn.Linear(d_model, num_classes + 1)  \n",
    "        self.bbox_embed = MLP(d_model, d_model, 4, 3)\n",
    "\n",
    "    def forward(self, x_ol, x_sd):\n",
    "        # backbone\n",
    "        f_ol = self.backbone(x_ol)    # [B,256,H',W']\n",
    "        f_sd = self.backbone(x_sd)    # [B,256,H',W']\n",
    "\n",
    "        # positional encoding\n",
    "        pos = self.pos_enc(f_ol)      \n",
    "        B, C, H, W = f_ol.shape\n",
    "\n",
    "        # flatten -> [N,B,C]\n",
    "        N = H * W\n",
    "        src_main = f_ol.flatten(2).permute(2, 0, 1)  # [N,B,C]\n",
    "        src_asst = f_sd.flatten(2).permute(2, 0, 1)  # [N,B,C]\n",
    "        pos_flat = pos.flatten(2).permute(2, 0, 1)      # [N,B,C]\n",
    "\n",
    "      \n",
    "        pos_cat = torch.cat([pos_flat, pos_flat], dim=1)  # [N,2B,C]\n",
    "\n",
    "        src = torch.cat([src_main, src_asst], dim=1)      # [N,2B,C]\n",
    "        memory = self.encoder(src, pos=pos_cat)           # ‚úÖ\n",
    "\n",
    "\n",
    "        # decoder\n",
    "        query_pos = self.query_embed.weight.unsqueeze(1).repeat(1, B, 1)  # [Q,B,C]\n",
    "        tgt = torch.zeros_like(query_pos)                                 # [Q,B,C]\n",
    "        hs = self.decoder(tgt, memory, pos=pos_flat, query_pos=query_pos)\n",
    "\n",
    "        # predictions\n",
    "        outputs_class = self.class_embed(hs).permute(1, 0, 2)  # [B,Q,K+1]\n",
    "        outputs_coord = self.bbox_embed(hs).sigmoid().permute(1, 0, 2)  # [B,Q,4] normalized cxcywh\n",
    "\n",
    "        return {\"pred_logits\": outputs_class, \"pred_boxes\": outputs_coord}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed0c5c",
   "metadata": {},
   "source": [
    "## üìä Model Summary\n",
    "\n",
    "- Set device (`cuda` if available, else `cpu`).\n",
    "- Instantiate `Trans2RayModel` and move to device.\n",
    "- Use `torchinfo.summary` to inspect model:\n",
    "  - Inputs: OL & SD images `[1,3,512,512]`\n",
    "  - Columns: input size, output size, number of parameters, trainable status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14b984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "Trans2RayModel                                          [1, 3, 512, 512]          [1, 100, 4]               25,600                    Partial\n",
       "‚îú‚îÄResNetBackbone: 1-1                                   [1, 3, 512, 512]          [1, 256, 16, 16]          --                        Partial\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-1                                  [1, 3, 512, 512]          [1, 64, 128, 128]         --                        False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                                 [1, 3, 512, 512]          [1, 64, 256, 256]         (9,408)                   False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2                            [1, 64, 256, 256]         [1, 64, 256, 256]         (128)                     False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-3                                   [1, 64, 256, 256]         [1, 64, 256, 256]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-4                              [1, 64, 256, 256]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-2                                  [1, 64, 128, 128]         [1, 64, 128, 128]         --                        False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-5                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-1                            [1, 64, 128, 128]         [1, 64, 128, 128]         (36,864)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-2                       [1, 64, 128, 128]         [1, 64, 128, 128]         (128)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-3                              [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-4                            [1, 64, 128, 128]         [1, 64, 128, 128]         (36,864)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-5                       [1, 64, 128, 128]         [1, 64, 128, 128]         (128)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-6                              [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-6                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-7                            [1, 64, 128, 128]         [1, 64, 128, 128]         (36,864)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-8                       [1, 64, 128, 128]         [1, 64, 128, 128]         (128)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-9                              [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-10                           [1, 64, 128, 128]         [1, 64, 128, 128]         (36,864)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-11                      [1, 64, 128, 128]         [1, 64, 128, 128]         (128)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-12                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-3                                  [1, 64, 128, 128]         [1, 128, 64, 64]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-7                             [1, 64, 128, 128]         [1, 128, 64, 64]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-13                           [1, 64, 128, 128]         [1, 128, 64, 64]          (73,728)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-14                      [1, 128, 64, 64]          [1, 128, 64, 64]          (256)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-15                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-16                           [1, 128, 64, 64]          [1, 128, 64, 64]          (147,456)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-17                      [1, 128, 64, 64]          [1, 128, 64, 64]          (256)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-18                       [1, 64, 128, 128]         [1, 128, 64, 64]          (8,448)                   False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-19                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-8                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-20                           [1, 128, 64, 64]          [1, 128, 64, 64]          (147,456)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-21                      [1, 128, 64, 64]          [1, 128, 64, 64]          (256)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-22                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-23                           [1, 128, 64, 64]          [1, 128, 64, 64]          (147,456)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-24                      [1, 128, 64, 64]          [1, 128, 64, 64]          (256)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-25                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-4                                  [1, 128, 64, 64]          [1, 256, 32, 32]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-9                             [1, 128, 64, 64]          [1, 256, 32, 32]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-26                           [1, 128, 64, 64]          [1, 256, 32, 32]          (294,912)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-27                      [1, 256, 32, 32]          [1, 256, 32, 32]          (512)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-28                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-29                           [1, 256, 32, 32]          [1, 256, 32, 32]          (589,824)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-30                      [1, 256, 32, 32]          [1, 256, 32, 32]          (512)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-31                       [1, 128, 64, 64]          [1, 256, 32, 32]          (33,280)                  False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-32                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-10                            [1, 256, 32, 32]          [1, 256, 32, 32]          --                        False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-33                           [1, 256, 32, 32]          [1, 256, 32, 32]          (589,824)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-34                      [1, 256, 32, 32]          [1, 256, 32, 32]          (512)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-35                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-36                           [1, 256, 32, 32]          [1, 256, 32, 32]          (589,824)                 False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-37                      [1, 256, 32, 32]          [1, 256, 32, 32]          (512)                     False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-38                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-5                                  [1, 256, 32, 32]          [1, 512, 16, 16]          --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-11                            [1, 256, 32, 32]          [1, 512, 16, 16]          --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-39                           [1, 256, 32, 32]          [1, 512, 16, 16]          1,179,648                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-40                      [1, 512, 16, 16]          [1, 512, 16, 16]          1,024                     True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-41                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-42                           [1, 512, 16, 16]          [1, 512, 16, 16]          2,359,296                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-43                      [1, 512, 16, 16]          [1, 512, 16, 16]          1,024                     True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-44                       [1, 256, 32, 32]          [1, 512, 16, 16]          132,096                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-45                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-12                            [1, 512, 16, 16]          [1, 512, 16, 16]          --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-46                           [1, 512, 16, 16]          [1, 512, 16, 16]          2,359,296                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-47                      [1, 512, 16, 16]          [1, 512, 16, 16]          1,024                     True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-48                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-49                           [1, 512, 16, 16]          [1, 512, 16, 16]          2,359,296                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-50                      [1, 512, 16, 16]          [1, 512, 16, 16]          1,024                     True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-51                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-6                                      [1, 512, 16, 16]          [1, 256, 16, 16]          131,328                   True\n",
       "‚îú‚îÄResNetBackbone: 1-2                                   [1, 3, 512, 512]          [1, 256, 16, 16]          (recursive)               Partial\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-7                                  [1, 3, 512, 512]          [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                                [1, 3, 512, 512]          [1, 64, 256, 256]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-14                           [1, 64, 256, 256]         [1, 64, 256, 256]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-15                                  [1, 64, 256, 256]         [1, 64, 256, 256]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-16                             [1, 64, 256, 256]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-8                                  [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-17                            [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-52                           [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-53                      [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-54                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-55                           [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-56                      [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-57                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-18                            [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-58                           [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-59                      [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-60                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-61                           [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-62                      [1, 64, 128, 128]         [1, 64, 128, 128]         (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-63                             [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-9                                  [1, 64, 128, 128]         [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-19                            [1, 64, 128, 128]         [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-64                           [1, 64, 128, 128]         [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-65                      [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-66                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-67                           [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-68                      [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-69                       [1, 64, 128, 128]         [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-70                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-20                            [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-71                           [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-72                      [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-73                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-74                           [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-75                      [1, 128, 64, 64]          [1, 128, 64, 64]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-76                             [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-10                                 [1, 128, 64, 64]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-21                            [1, 128, 64, 64]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-77                           [1, 128, 64, 64]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-78                      [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-79                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-80                           [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-81                      [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-82                       [1, 128, 64, 64]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-83                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-22                            [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-84                           [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-85                      [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-86                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-87                           [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-88                      [1, 256, 32, 32]          [1, 256, 32, 32]          (recursive)               False\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-89                             [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-11                                 [1, 256, 32, 32]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-23                            [1, 256, 32, 32]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-90                           [1, 256, 32, 32]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-91                      [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-92                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-93                           [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-94                      [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-95                       [1, 256, 32, 32]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-96                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBasicBlock: 3-24                            [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-97                           [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-98                      [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-99                             [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-100                          [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 4-101                     [1, 512, 16, 16]          [1, 512, 16, 16]          (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-102                            [1, 512, 16, 16]          [1, 512, 16, 16]          --                        --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-12                                     [1, 512, 16, 16]          [1, 256, 16, 16]          (recursive)               True\n",
       "‚îú‚îÄPositionEmbeddingSine: 1-3                            [1, 256, 16, 16]          [1, 256, 16, 16]          --                        --\n",
       "‚îú‚îÄCVFFTransformerEncoder: 1-4                           [256, 2, 256]             [256, 1, 256]             --                        True\n",
       "‚îÇ    ‚îî‚îÄCrossBlock: 2-13                                 [512, 1, 256]             [256, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄCrossAttention: 3-25                        [512, 1, 256]             [256, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-103                          [1, 256, 256]             [1, 256, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-104                          [1, 512, 256]             [1, 512, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-105                          [1, 512, 256]             [1, 512, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-106                         [1, 8, 256, 512]          [1, 8, 256, 512]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-107                          [1, 256, 256]             [1, 256, 256]             65,792                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-108                         [1, 256, 256]             [1, 256, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-26                               [256, 1, 256]             [256, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄCrossBlock: 2-14                                 [512, 1, 256]             [256, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄCrossAttention: 3-27                        [512, 1, 256]             [256, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-109                          [1, 256, 256]             [1, 256, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-110                          [1, 512, 256]             [1, 512, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-111                          [1, 512, 256]             [1, 512, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-112                         [1, 8, 256, 512]          [1, 8, 256, 512]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-113                          [1, 256, 256]             [1, 256, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-114                         [1, 256, 256]             [1, 256, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-28                               [256, 1, 256]             [256, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-29               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-115              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-116                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-117                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-118                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-119                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-120                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-121                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-122                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-123                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-16                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-17                                      [257, 1, 256]             [257, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-30                             [257, 1, 256]             [257, 1, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-31                             [257, 1, 256]             [257, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-124                          [1, 257, 256]             [1, 257, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-125                          [1, 257, 256]             [1, 257, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-126                          [1, 257, 256]             [1, 257, 256]             65,536                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-127                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-128                          [1, 257, 256]             [1, 257, 256]             65,792                    True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-129                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-32                             [257, 1, 256]             [257, 1, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-33                                   [257, 1, 256]             [257, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-130                          [257, 1, 256]             [257, 1, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-131                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-132                          [257, 1, 1024]            [257, 1, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-133                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-18                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-34               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-134              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-135                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-136                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-137                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-138                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-139                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-140                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-141                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-142                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-20                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-21                                      [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-35                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-36                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-143                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-144                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-145                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-146                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-147                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-148                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-37                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-38                                   [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-149                          [257, 1, 256]             [257, 1, 1024]            (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-150                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-151                          [257, 1, 1024]            [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-152                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-22                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-39               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-153              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-154                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-155                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-156                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-157                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-158                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-159                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-160                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-161                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-24                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-25                                      [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-40                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-41                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-162                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-163                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-164                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-165                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-166                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-167                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-42                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-43                                   [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-168                          [257, 1, 256]             [257, 1, 1024]            (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-169                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-170                          [257, 1, 1024]            [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-171                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-26                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-44               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-172              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-173                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-174                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-175                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-176                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-177                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-178                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-179                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-180                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-28                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-29                                      [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-45                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-46                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-181                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-182                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-183                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-184                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-185                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-186                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-47                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-48                                   [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-187                          [257, 1, 256]             [257, 1, 1024]            (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-188                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-189                          [257, 1, 1024]            [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-190                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-30                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-49               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-191              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-192                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-193                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-194                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-195                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-196                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-197                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-198                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-199                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-32                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-33                                      [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-50                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-51                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-200                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-201                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-202                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-203                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-204                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-205                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-52                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-53                                   [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-206                          [257, 1, 256]             [257, 1, 1024]            (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-207                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-208                          [257, 1, 1024]            [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-209                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-34                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-35                                 --                        --                        (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-54               [256, 2, 256]             [256, 2, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 4-210              [256, 2, 256]             [256, 2, 256]             263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-211                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-212                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-213                          [256, 2, 256]             [256, 2, 1024]            263,168                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 4-214                            [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-215                         [256, 2, 1024]            [256, 2, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-216                          [256, 2, 1024]            [256, 2, 256]             262,400                   True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-217                         [256, 2, 256]             [256, 2, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-218                       [256, 2, 256]             [256, 2, 256]             512                       True\n",
       "‚îÇ    ‚îî‚îÄAdaptiveAvgPool1d: 2-36                          [1, 256, 256]             [1, 256, 1]               --                        --\n",
       "‚îÇ    ‚îî‚îÄBlock: 2-37                                      [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-55                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄAttention: 3-56                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-219                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-220                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-221                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-222                         [1, 8, 257, 257]          [1, 8, 257, 257]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-223                          [1, 257, 256]             [1, 257, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-224                         [1, 257, 256]             [1, 257, 256]             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-57                             [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMlp: 3-58                                   [257, 1, 256]             [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-225                          [257, 1, 256]             [257, 1, 1024]            (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-226                         [257, 1, 1024]            [257, 1, 1024]            --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 4-227                          [257, 1, 1024]            [257, 1, 256]             (recursive)               True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-228                         [257, 1, 256]             [257, 1, 256]             --                        --\n",
       "‚îÇ    ‚îî‚îÄMAWS: 2-38                                       [1, 8, 257, 257]          --                        --                        --\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-39                                  [256, 1, 256]             [256, 1, 256]             512                       True\n",
       "‚îú‚îÄDETRDecoder: 1-5                                      [100, 1, 256]             [100, 1, 256]             --                        True\n",
       "‚îÇ    ‚îî‚îÄTransformerDecoder: 2-40                         [100, 1, 256]             [100, 1, 256]             --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-59                            --                        --                        --                        True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-229         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-230         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-231         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-232         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-233         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer: 4-234         [100, 1, 256]             [100, 1, 256]             1,053,440                 True\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-41                                  [100, 1, 256]             [100, 1, 256]             512                       True\n",
       "‚îú‚îÄLinear: 1-6                                           [100, 1, 256]             [100, 1, 16]              4,112                     True\n",
       "‚îú‚îÄMLP: 1-7                                              [100, 1, 256]             [100, 1, 4]               --                        True\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-42                                 --                        --                        --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-60                                [100, 1, 256]             [100, 1, 256]             65,792                    True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-61                                [100, 1, 256]             [100, 1, 256]             65,792                    True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-62                                [100, 1, 256]             [100, 1, 4]               1,028                     True\n",
       "===========================================================================================================================================================\n",
       "Total params: 23,581,780\n",
       "Trainable params: 20,798,996\n",
       "Non-trainable params: 2,782,784\n",
       "Total mult-adds (G): 20.97\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 512.34\n",
       "Params size (MB): 75.28\n",
       "Estimated Total Size (MB): 593.91\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Trans2RayModel(num_classes=15, num_queries=100, d_model=256, nhead=8, enc_layers=6, dec_layers=6).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=[(1, 3, 512, 512), (1, 3, 512, 512)],  # x_ol , x_sd\n",
    "    depth=4,\n",
    "    col_names=[\n",
    "        \"input_size\",\n",
    "        \"output_size\",\n",
    "        \"num_params\",\n",
    "        \"trainable\"\n",
    "    ],\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83545eb4",
   "metadata": {},
   "source": [
    "## üß© Hungarian Matcher & SetCriterion\n",
    "\n",
    "- **HungarianMatcher**:\n",
    "  - Matches predicted boxes and classes to targets using the Hungarian algorithm.\n",
    "  - Computes a cost matrix combining:\n",
    "    - Classification cost (`-P(class)`)\n",
    "    - L1 distance for bounding boxes\n",
    "    - Generalized IoU\n",
    "  - Returns indices of matched predictions and targets.\n",
    "\n",
    "- **SetCriterion**:\n",
    "  - Computes losses for DETR-style predictions.\n",
    "  - Losses:\n",
    "    - `loss_labels`: cross-entropy over predicted classes with \"no-object\" weighting.\n",
    "    - `loss_boxes`: L1 loss for bounding boxes + GIoU loss.\n",
    "  - `forward` matches predictions to targets and sums weighted losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HungarianMatcher(nn.Module):\n",
    "    def __init__(self, cost_class=1.0, cost_bbox=5.0, cost_giou=2.0):\n",
    "        super().__init__()\n",
    "        # Set weights for each type of cost\n",
    "        self.cost_class = cost_class\n",
    "        self.cost_bbox = cost_bbox\n",
    "        self.cost_giou = cost_giou\n",
    "        assert cost_class != 0 or cost_bbox != 0 or cost_giou != 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Match predicted boxes to targets using Hungarian algorithm.\n",
    "        outputs: dict with pred_logits [B,Q,K+1], pred_boxes [B,Q,4]\n",
    "        targets: list of dicts, each with labels [N], boxes_ol [N,4]\n",
    "        \"\"\"\n",
    "        bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n",
    "        out_prob = outputs[\"pred_logits\"].softmax(-1)  # classification probabilities\n",
    "        out_bbox = outputs[\"pred_boxes\"]               # predicted boxes\n",
    "\n",
    "        indices = []\n",
    "        for b in range(bs):\n",
    "            tgt_ids = targets[b][\"labels\"].to(out_bbox.device)\n",
    "            tgt_bbox = targets[b][\"boxes_ol\"].to(out_bbox.device)\n",
    "\n",
    "            if tgt_ids.numel() == 0:\n",
    "                # No targets: return empty match\n",
    "                indices.append((torch.empty(0, dtype=torch.int64), torch.empty(0, dtype=torch.int64)))\n",
    "                continue\n",
    "\n",
    "            # classification cost: -P(class)\n",
    "            cost_class = -out_prob[b][:, tgt_ids]  # [Q, Nt]\n",
    "\n",
    "            # bbox L1 cost\n",
    "            cost_bbox = torch.cdist(out_bbox[b], tgt_bbox, p=1)  # [Q, Nt]\n",
    "\n",
    "            # giou cost\n",
    "            out_xyxy = box_cxcywh_to_xyxy(out_bbox[b])\n",
    "            tgt_xyxy = box_cxcywh_to_xyxy(tgt_bbox)\n",
    "            cost_giou = -generalized_box_iou(out_xyxy, tgt_xyxy)  # [Q,Nt]\n",
    "\n",
    "            # final cost matrix\n",
    "            C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou\n",
    "            C = C.cpu()\n",
    "\n",
    "            # Hungarian algorithm\n",
    "            i, j = linear_sum_assignment(C)\n",
    "            indices.append((torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)))\n",
    "\n",
    "        return indices\n",
    "\n",
    "\n",
    "class SetCriterion(nn.Module):\n",
    "    def __init__(self, num_classes, matcher, weight_dict, eos_coef=0.1):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.matcher = matcher\n",
    "        self.weight_dict = weight_dict\n",
    "        self.eos_coef = eos_coef\n",
    "\n",
    "        # Weight for \"no-object\" class\n",
    "        empty_weight = torch.ones(num_classes + 1).to(device)\n",
    "        empty_weight[-1] = eos_coef\n",
    "        self.register_buffer(\"empty_weight\", empty_weight)\n",
    "\n",
    "    def loss_labels(self, outputs, targets, indices):\n",
    "        src_logits = outputs[\"pred_logits\"]  # [B, Q, K+1]\n",
    "        bs, Q, _ = src_logits.shape\n",
    "\n",
    "        # Default: all \"no-object\"\n",
    "        target_classes = torch.full((bs, Q), self.num_classes, dtype=torch.int64, device=src_logits.device)\n",
    "\n",
    "        # Assign matched classes\n",
    "        for b, (src_idx, tgt_idx) in enumerate(indices):\n",
    "            if src_idx.numel() == 0:\n",
    "                continue\n",
    "            target_classes[b, src_idx] = targets[b][\"labels\"][tgt_idx].to(src_logits.device)\n",
    "\n",
    "        # Cross-entropy loss with weighting\n",
    "        loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, weight=self.empty_weight)\n",
    "        return {\"loss_ce\": loss_ce}\n",
    "\n",
    "    def loss_boxes(self, outputs, targets, indices):\n",
    "        src_boxes = outputs[\"pred_boxes\"]  # [B, Q, 4]\n",
    "        bs, Q, _ = src_boxes.shape\n",
    "\n",
    "        loss_bbox = torch.tensor(0., device=src_boxes.device)\n",
    "        loss_giou = torch.tensor(0., device=src_boxes.device)\n",
    "\n",
    "        # Compute bbox L1 and giou losses\n",
    "        for b, (src_idx, tgt_idx) in enumerate(indices):\n",
    "            if src_idx.numel() == 0:\n",
    "                continue\n",
    "            sb = src_boxes[b, src_idx]\n",
    "            tb = targets[b][\"boxes_ol\"][tgt_idx].to(src_boxes.device)\n",
    "\n",
    "            loss_bbox = loss_bbox + F.l1_loss(sb, tb, reduction=\"sum\") / max(tb.shape[0], 1)\n",
    "\n",
    "            giou = generalized_box_iou(box_cxcywh_to_xyxy(sb), box_cxcywh_to_xyxy(tb))\n",
    "            loss_giou = loss_giou + (1 - giou.diag()).mean()\n",
    "\n",
    "        return {\"loss_bbox\": loss_bbox, \"loss_giou\": loss_giou}\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # Match predictions to targets\n",
    "        indices = self.matcher(outputs, targets)\n",
    "        losses = {}\n",
    "\n",
    "        # Compute classification and bbox losses\n",
    "        losses.update(self.loss_labels(outputs, targets, indices))\n",
    "        losses.update(self.loss_boxes(outputs, targets, indices))\n",
    "\n",
    "        # Weighted sum\n",
    "        total = 0.0\n",
    "        for k, v in losses.items():\n",
    "            total += self.weight_dict.get(k, 1.0) * v\n",
    "        losses[\"loss_total\"] = total\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6b56d",
   "metadata": {},
   "source": [
    "## ‚ö° Setup for Training\n",
    "\n",
    "- **Device**: CUDA if available, else CPU\n",
    "- **Model**: Trans2RayModel with 15 classes, 100 queries, 256-dim features\n",
    "- **Matcher**: HungarianMatcher (weights: class=1, bbox=5, giou=2)\n",
    "- **Criterion**: SetCriterion with weighted losses\n",
    "- **Optimizer**: AdamW (lr=1e-4, weight_decay=1e-4)\n",
    "- **Scheduler**: StepLR (step every 20 epochs, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = Trans2RayModel(num_classes=15, num_queries=100, d_model=256, nhead=8, enc_layers=6, dec_layers=6).to(device)\n",
    "matcher = HungarianMatcher(cost_class=1, cost_bbox=5, cost_giou=2)\n",
    "criterion = SetCriterion(\n",
    "    num_classes=15,\n",
    "    matcher=matcher,\n",
    "    weight_dict={\"loss_ce\": 1.0, \"loss_bbox\": 5.0, \"loss_giou\": 2.0},\n",
    "    eos_coef=0.1\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=20,\n",
    "    gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ac5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, val_loss, filename=\"checkpoint.pth\"):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"val_loss\": val_loss,\n",
    "    }, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    val_loss = checkpoint[\"val_loss\"]\n",
    "    return model, optimizer, epoch, val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9d821",
   "metadata": {},
   "source": [
    "## Training Loop (Summary)\n",
    "\n",
    "- Device: CUDA if available  \n",
    "- Epochs: 50, grad clip: 0.1, log every 10 steps  \n",
    "- Best model saved to `best_model.pth`  \n",
    "- CSV log: `training_log.csv`\n",
    "\n",
    "### Steps per Epoch:\n",
    "1. **Train**: forward, loss, backprop, gradient clip, optimizer step, log  \n",
    "2. **Validation**: eval mode, no grad, compute losses  \n",
    "3. **Checkpoint**: save if val loss improves  \n",
    "4. **Log**: append losses to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0aff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2510/6400 [10:37<49:18,  1.31it/s, L=1.7847, CE=0.3378, B=0.1149, G=0.4362, lr=0.0001]  "
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# training config\n",
    "# -------------------------\n",
    "num_epochs = 50\n",
    "grad_clip = 0.1\n",
    "log_every = 10\n",
    "save_path = \"best_model.pth\"\n",
    "best_val_loss = float('inf')\n",
    "log_file = \"training_log.csv\"\n",
    "\n",
    "# ----------- create log file with header if not exists -----------\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss_total\", \"train_loss_ce\", \"train_loss_bbox\", \"train_loss_giou\",\n",
    "            \"val_loss_total\", \"val_loss_ce\", \"val_loss_bbox\", \"val_loss_giou\"\n",
    "        ])\n",
    "\n",
    "# -------------------------\n",
    "# training loop\n",
    "# -------------------------\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # =========================\n",
    "    # TRAIN\n",
    "    # =========================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_ce = 0.0\n",
    "    running_bbox = 0.0\n",
    "    running_giou = 0.0\n",
    "\n",
    "    pbar = tqdm(dl_train, desc=f\"Epoch [{epoch+1}/{num_epochs}] Train\")\n",
    "    for step, (x_ol, x_sd, targets) in enumerate(pbar):\n",
    "\n",
    "        x_ol = x_ol.to(device)\n",
    "        x_sd = x_sd.to(device)\n",
    "\n",
    "        outputs = model(x_ol, x_sd)\n",
    "        losses = criterion(outputs, targets)\n",
    "        loss = losses[\"loss_total\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_ce += losses[\"loss_ce\"].item()\n",
    "        running_bbox += losses[\"loss_bbox\"].item()\n",
    "        running_giou += losses[\"loss_giou\"].item()\n",
    "\n",
    "        if (step + 1) % log_every == 0:\n",
    "            pbar.set_postfix({\n",
    "                \"L\": f\"{running_loss / (step + 1):.4f}\",\n",
    "                \"CE\": f\"{running_ce / (step + 1):.4f}\",\n",
    "                \"B\": f\"{running_bbox / (step + 1):.4f}\",\n",
    "                \"G\": f\"{running_giou / (step + 1):.4f}\",\n",
    "                \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "            })\n",
    "\n",
    "    train_loss_total = running_loss / len(dl_train)\n",
    "    train_loss_ce = running_ce / len(dl_train)\n",
    "    train_loss_bbox = running_bbox / len(dl_train)\n",
    "    train_loss_giou = running_giou / len(dl_train)\n",
    "\n",
    "    # =========================\n",
    "    # VALIDATION\n",
    "    # =========================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_ce = 0.0\n",
    "    val_bbox = 0.0\n",
    "    val_giou = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_ol, x_sd, targets in tqdm(\n",
    "            dl_val, desc=f\"Epoch [{epoch+1}/{num_epochs}] Val\"\n",
    "        ):\n",
    "            x_ol = x_ol.to(device)\n",
    "            x_sd = x_sd.to(device)\n",
    "\n",
    "            outputs = model(x_ol, x_sd)\n",
    "            losses = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += losses[\"loss_total\"].item()\n",
    "            val_ce += losses[\"loss_ce\"].item()\n",
    "            val_bbox += losses[\"loss_bbox\"].item()\n",
    "            val_giou += losses[\"loss_giou\"].item()\n",
    "\n",
    "    val_loss_total = val_loss / len(dl_val)\n",
    "    val_loss_ce = val_ce / len(dl_val)\n",
    "    val_loss_bbox = val_bbox / len(dl_val)\n",
    "    val_loss_giou = val_giou / len(dl_val)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train | total: {train_loss_total:.4f} | ce: {train_loss_ce:.4f} | \"\n",
    "          f\"bbox: {train_loss_bbox:.4f} | giou: {train_loss_giou:.4f}\")\n",
    "    print(f\"  Val   | total: {val_loss_total:.4f} | ce: {val_loss_ce:.4f} | \"\n",
    "          f\"bbox: {val_loss_bbox:.4f} | giou: {val_loss_giou:.4f}\")\n",
    "\n",
    "    # =========================\n",
    "    # SAVE BEST MODEL\n",
    "    # =========================\n",
    "    if val_loss_total < best_val_loss:\n",
    "        best_val_loss = val_loss_total\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"‚úÖ Best model saved (epoch {epoch+1})\")\n",
    "\n",
    "    # =========================\n",
    "    # CSV LOGGING\n",
    "    # =========================\n",
    "    with open(log_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            train_loss_total, train_loss_ce, train_loss_bbox, train_loss_giou,\n",
    "            val_loss_total, val_loss_ce, val_loss_bbox, val_loss_giou\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
